# Fine-Tuning Pipeline for Handwriting Recognition

This folder contains everything needed to fine-tune OCR models (TrOCR or LaTeX-OCR/pix2tex) on your handwriting for better accuracy.

## ğŸ¯ Two Options

### Option 1: Pix2tex (LaTeX-OCR) - Recommended for Complex Math

**Best for:** Fractions, integrals, complex mathematical expressions

```bash
cd tests
./pix2tex_pipeline.sh
```

This one command will:
1. Collect data from `../written_answers/`
2. Preprocess images
3. Convert to pix2tex format
4. Generate tokenizer
5. Create pickle datasets
6. Fine-tune pix2tex model

**Output:** `checkpoints/pix2tex/` (fine-tuned model)

---

### Option 2: TrOCR - Simpler for Digits/Simple Equations

**Best for:** Simple numbers, basic arithmetic

```bash
cd tests
pip install -r requirements.txt
./train.sh
```

Or step by step:
```bash
python scripts/01_collect_data.py    # Collect data
python scripts/02_preprocess.py      # Preprocess images
python scripts/03_finetune_trocr.py # Fine-tune TrOCR
python scripts/04_evaluate.py        # Evaluate
python scripts/05_inference.py path/to/image.png  # Test
```

**Output:** `models/trocr-finetuned/` (fine-tuned model)

---

## ğŸ“ Folder Structure

```
tests/
â”œâ”€â”€ scripts/                    # All training scripts
â”‚   â”œâ”€â”€ 01_collect_data.py     # Collect from written_answers/
â”‚   â”œâ”€â”€ 02_preprocess.py       # Preprocess images
â”‚   â”œâ”€â”€ 03_finetune_trocr.py   # Fine-tune TrOCR
â”‚   â”œâ”€â”€ 04_evaluate.py         # Evaluate performance
â”‚   â”œâ”€â”€ 05_inference.py        # Test on new images
â”‚   â”œâ”€â”€ 06_prepare_pix2tex_data.py  # Convert to pix2tex format
â”‚   â””â”€â”€ 07_create_pix2tex_dataset.py # Create pix2tex pickle files
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ train.yaml             # Pix2tex training config
â”‚
â”œâ”€â”€ data/                      # Source training data (generated)
â”‚   â”œâ”€â”€ train/images/ + labels.txt
â”‚   â””â”€â”€ val/images/ + labels.txt
â”‚
â”œâ”€â”€ dataset/                   # Pix2tex format (generated)
â”‚   â”œâ”€â”€ images/train/, val/
â”‚   â”œâ”€â”€ data/*.pkl + equations.txt
â”‚   â””â”€â”€ tokenizer.json
â”‚
â”œâ”€â”€ checkpoints/               # Pix2tex fine-tuned models (generated)
â”œâ”€â”€ models/                    # TrOCR fine-tuned models (generated)
â”‚
â”œâ”€â”€ pix2tex_pipeline.sh        # Complete pix2tex pipeline
â”œâ”€â”€ train.sh                   # Complete TrOCR pipeline
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

---

## ğŸ“Š Data Format

### Source Data (Auto-Generated)

Scripts automatically create `labels.txt` files with format:
```
image_name.png\tlabel_text
```

Example:
```
addition_1_20241101_120000.png\t11
integrals_5_20241101_153029.png\t{{4/7 x^7 - 1/2 x^4 + 7/2 x^2 - 4x + c}}
```

### Pix2tex Format (Auto-Generated)

- **Equations file**: One equation per line in `dataset/data/train_equations.txt`
- **Images**: Numbered as `0.png`, `1.png`, etc. in `dataset/images/train/`
- **Pickle datasets**: `dataset/data/train.pkl`, `val.pkl`

---

## âš™ï¸ Configuration

### Pix2tex Config

Edit `configs/train.yaml`:
- `epochs`: Number of training epochs (default: 5)
- `batchsize`: Batch size (default: 4 for small datasets)
- `lr`: Learning rate (default: 0.001)

### TrOCR Config

Edit `config.yaml` (for TrOCR):
- `training.num_train_epochs`: Number of epochs (default: 5)
- `training.learning_rate`: Learning rate (default: 5e-5)
- `training.per_device_train_batch_size`: Batch size (default: 4)

---

## ğŸ”§ Integration into App

After fine-tuning, update `app.py`:

### For Pix2tex:
```python
from pix2tex.api import latex
model = latex.LatexOCR()
# Load your checkpoint
model.load_checkpoint("tests/checkpoints/pix2tex/pix2tex_e05_step00.pth")
```

### For TrOCR:
```python
from transformers import VisionEncoderDecoderModel, TrOCRProcessor

model = VisionEncoderDecoderModel.from_pretrained("./tests/models/trocr-finetuned")
processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
```

---

## ğŸ’¡ Tips

1. **Start small**: Even 50-100 examples can show improvement
2. **Iterate**: Run evaluation, find errors, add those examples to training
3. **Monitor**: Check training logs for progress
4. **GPU**: Training is much faster with GPU (set `gpu_devices: [0]` in config)

---

## ğŸ› Troubleshooting

**Out of memory?**
- Reduce `batchsize` in config

**Low accuracy?**
- Add more training examples
- Increase `epochs`
- Adjust `lr` (try 0.0005 or 0.002)

**Training takes too long?**
- Reduce `epochs`
- Use GPU if available

**"No images found" error?**
- Make sure images are in `../written_answers/` folder
- Check image naming format: `{category}_{id}_{timestamp}.png`

---

## ğŸ“ What Gets Generated

**Keep in Git:**
- âœ… All scripts
- âœ… Config files
- âœ… README.md

**Don't Commit (add to .gitignore):**
- âŒ `wandb/` (experiment tracking)
- âŒ `__pycache__/` (Python cache)
- âŒ `data/` (source training data - can be regenerated)
- âŒ `dataset/` (pix2tex format - can be regenerated)
- âŒ `checkpoints/` (trained models - large files)
- âŒ `models/` (trained models - large files)
